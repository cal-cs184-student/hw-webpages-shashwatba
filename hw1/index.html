<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
		<h1>CS184/284A Spring 2025 Homework 1 Write-Up</h1>
		<div style="text-align: center;">Shashwat Bansal</div>

		<br>

		Link to webpage: <a href="https://cal-cs184-student.github.io/hw-webpages-shashwatba/hw1/index.html">https://cal-cs184-student.github.io/hw-webpages-shashwatba/hw1/index.html</a>
		
		<br>

		Link to GitHub repository: <a href="https://github.com/cal-cs184-student/sp25-hw1-shashwat">https://github.com/cal-cs184-student/sp25-hw1-shashwat</a>

		<!--
		We've already added one heading per task, to make your write-up as navigable when grading. Please fit your write-up within these sections!
		-->

		<h2>Overview</h2>
		<p>In this project, I wrote code which renders images from .svg files, primarily using triangle rasterization. I also implemented different sampling techniques and evaluated their drawbacks and benefits.</p>
		<h2>Task 1: Drawing Single-Color Triangles</h2>
		<p>For my basic implementation, I used the idea from lecture 2 of looping through the raster grid and checking each pixel’s midpoint, using a function called is_inside_triangle which returns true if the pixel needs to be colored and false if not. To ensure that the entire triangle is within the raster grid, I first computed min_x, min_y, max_x and max_y, which are the x and y edges of the triangle computed using the input vertices. If is_inside_triangle returns true, the rasterize_triangle function colors that pixel. To implement the actual is_inside_triangle function, I ran the line equation tests but was running into the issue of clockwise vertex orderings not returning “true”. To fix this, I used an idea from Discussion 2: flip any two vertices to change the winding order from clockwise to anti-clockwise in the case that (x1 - x0) * (y2 - y1) - (x2 - x1) * (y1 - y0) < 0, indicating a negative z-axis as per the right hand rule.
		</p><p>
		In cases where the triangle covers most of its bounding box (e.g., large triangles), the performance of this approach is comparable to the bounding box method since most pixels need to be processed. However, it is never worse because the overhead of additional checks is minimal compared to the savings in typical scenarios.
	</p><figure>
			<img src="t1.png" alt="test4" width="400px"/>
			<figcaption>Task 1</figcaption>
		</figure>

		<h2>Task 1: Extra Credit (Optimizations)</h2>
		<table>
			<thead>
				<tr>
					<th>Test Number</th>
					<th>Unoptimized Runtime (seconds)</th>
					<th>Optimized Runtime (seconds)</th>
				</tr>
			</thead>
			<tbody>
				<tr>
					<td>test3.svg</td>
					<td>0.015</td>
					<td>0.007</td>
				</tr>
				<tr>
					<td>test4.svg</td>
					<td>0.001</td>
					<td>0</td>
				</tr>
				<tr>
					<td>test5.svg</td>
					<td>0.003</td>
					<td>0</td>
				</tr>
				<tr>
					<td>test6.svg</td>
					<td>0.002</td>
					<td>0</td>
				</tr>
			</tbody>
		</table>
	
		The main adjustment I made was one in which I implemented a way to reduce unnecessary checks for points outside the triangle, once I have hit the border. Within each iteration, I checked:
		
		<pre>
		if (inside) {
			if (!inside_found) {
				start_x = x; // mark left edge as found, and where it is
				inside_found = true;
			}
			end_x = x;  // mark right edge as found (with the rightmost point so far)
		}
		else if (inside_found) { // This means I shouldn't be iterating anymore since I found the triangle elsewhere, so I can safely break.
			break;
		}</pre>
		
		I repeat this for each row so that I don't keep iterating past the right edge, ever. Some minor adjustments I made were:
		<ul>
			<li>Fill in the sample buffer all at once, after iterating through each row. This might be faster due to spatial locality in the cache, as opposed to sample buffer memory accesses being interspersed with computations.</li>
			<li>Check the winding number <i>before</i> sampling all the points, swapping vertices only once.</li>
			<li>Remove helper functions to eliminate unnecessary memory accesses.</li>
			<li>Add the 0.5 offset only at the start of the loops (twice) rather than within each iteration.</li>
			<li>Precompute variables like <code>x1 - x0</code> into <code>diff_1</code>, <code>y2 - y1</code> into <code>diff_5</code>, etc., to reduce computations.</li>
		</ul>
		
		<h2>Task 2: Antialiasing by Supersampling</h2>
		<p>I supersampled triangles by changing my implementation in rasterize_triangle to sample at a higher rate, i.e. sample sample_rate times within each pixel. I kept track of these sampled subpixels inside the sample_buffer, which is now larger to account for width * height * sample_rate pixels. I did not call fill_pixel here, instead opting to directly modify the sample_buffer inside the quadruple for loops. For the lines and points, I modified the call to fill_pixel so that it knows how to correctly index into the sample_buffer and fill in entire pixels with the same line/point color, doing so by looping through the subpixels of the pixel in double for loops just like in rasterize_triangle. Lastly, when resolving to framebuffer, I averaged the subpixels of each pixel by looping through them and adding them to a color, then dividing by the sample_rate before putting the color in rgb_framebuffer_target.
		</p><p>
		Supersampling is useful because it allows for anti-aliasing the image, filtering out “jaggies” such as in the triangle corner seen below. By sampling at a higher frequency than the display has enough pixels for, then averaging those pixels, the overall effect is that the image is smoother and more realistic, since edges are blurred rather than being in staircase like patterns. The main part of the rasterization pipeline that was modified was the resolve_to_framebuffer() function, which needed to accommodate a sample_buffer size that is larger than the framebuffer size.
	</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="T2.1.png" width="400px"/>
				  <figcaption>Supersampling Rate = 1</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="T2.4.png" width="400px"/>
				  <figcaption>Supersampling Rate = 4</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="T2.16.png" width="400px"/>
				  <figcaption>Supersampling Rate = 16</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<h2>Task 2: Extra Credit (Jittered Sampling)</h2>
		<p> I implemented jittering by generating two random numbers between zero and one, then sampling the original image at that (x, y) coordinate within the subpixel (as opposed to at (0.5, 0.5) = the center). If you look closely, there are some slight gradient differences between the two images below.
			<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="with.png" width="400px"/>
				  <figcaption>Jittered Supersampling</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="without.png" width="400px"/>
				  <figcaption>Center Supersampling</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<h2>Task 3: Transforms</h2>
		I rotated the front half of cube man's left arm and his entire body so that it looks like he is swimming. He is either wearing a golden swimming cap or a scuba diving helmet. His right arm has been rotated to be in a downstroke, while his left is in an upstroke. His legs are elongated because he is wearing diving flippers.
		<figure>
			<img src="swimming.png" alt="Swimming Man" width="400px"/>
			<figcaption>Cube Man Swimming</figcaption>
		</figure>

		<h2>Task 3: Extra Credit (Rotations)</h2>
		<p>I implemented a rotate counter-clockwise button ('K') and a rotate clockwise button ('J'), both of which rotate the image by 90 degrees. To do so, I first centered the image to the origin (top-left), multiplied by the rotation matrix, then un-centered it by multiplying it by the inverse of the centering matrix. </p>
		<figure>
			<img src="T3EC.png" alt="Swimming Man" width="400px"/>
			<figcaption>Cube Man Waving after being rotated counter-clockwise with 'K'</figcaption>
		</figure>

		<h2>Task 4: Barycentric coordinates</h2>
		Barycentric coordinates are a way to track points with reference to the sides of a polygon (in this class, specifically only to the sides of a triangle). For example, the image below displays a triangle with each of its vertices given a maximum R, G or B value respectively, and all other points in between are colored as per their barycentric coordinates. The higher the alpha value is, the farther the point is to the red vertex, and therefore is less red itself, and similarly for other colors. The sum of alpha, beta and gamma, the three barycentric coordinates, must always be one because the points lie within the triangle, and if any of alpha, beta or gamma are equal to one then we are at the respective vertex (maximum closeness). Also, gamma = 1 - alpha - beta, so we really only need two additional points to compute where our point is.
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="T4.1.png" width="400px"/>
				  <figcaption>Triangle with barycentric color gradient</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="T4.2.png" width="400px"/>
				  <figcaption>Color wheel</figcaption>
				</td>
			  </tr>
			  
			</table>
		</div>
		<h2>Task 5: "Pixel sampling" for texture mapping</h2>
		<p>Pixel sampling is the process of sampling the texture in the uv-plane into the xy-plane, going through a non-linear map. Since the map is not linear, bilinear mapping requires a weighted average of the four closest points to the uv coordinate, depending on which part of the pixel the uv coordinate is closest to. In the rasterization function, I needed Barycentric coordinates to interpolate the uv coordinates for each pair of xy coordinates, doing so if the points were inside the triangle. Nearest sampling simply rounds the uv-coordinate to the nearest available integer values and samples it.
		</p><p>
		As seen below, bilinear sampling produces a smoother rendition of the image regardless of the sampling rate, with less distinct pixels in the streaks of the parrot. There might be a large difference between the two when the xy-plane is much larger than the uv-plane, in which case nearest neighbour will magnify the pixelation in the uv-plane further into the xy-plane, while bilinear will be relatively smooth. This is because 1 texel is mapping to more than 1 pixel, so sampling more than 1 texel as in the bilinear approach provides a more robust algorithm.
	</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="T5 Nearest 1.png" width="400px"/>
				  <figcaption>Nearest neighbour, sampling rate = 1.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="T5 Nearest 16.png" width="400px"/>
				  <figcaption>Nearest neighbour, sampling rate = 16.</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="T5 Bilinear 1.png" width="400px"/>
				  <figcaption>Bilinear, sampling rate = 1.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="T5 Bilinear 16.png" width="400px"/>
				  <figcaption>Bilinear, sampling rate = 16.</figcaption>
				</td>
			  </tr>
			</table>
		</div>

		<h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>
		<p>Level sampling refers to selecting the appropriate downsampled version of the original image (known as a mipmap) based on how much curvature, minimization or maximization the texture is going through.
		</p><p>
		To implement level sampling, I computed the differences (in barycentric coordinates) at each point from (x+1, y) and (x, y+1), allowing me to get the derivative terms. These terms keep track of how quickly the color is changing around any given point, and are necessary for the calculations as listed in the spec. While sampling the texture, I ensured that the point stays within the bounds of the mipmap, and then called the relevant function: <code>sample_nearest()</code> or <code>sample_bilinear()</code>. In the <code>L_LINEAR</code> case, I averaged two different calls to these functions, one at <code>floor(level)</code> and one at <code>ceil(level)</code>.
	</p><p>
		I used my code from Task 1: Extra credit to see which combinations are fastest, and which are slow. Bilinear pixel interpolation sampling seems to be the fastest way to get a smooth image, mainly because it simply does some averaging operations and doesn't actually increase the number of samples needed. On the other hand, increasing the number of samples per pixel appears the slowest because of how many computations are needed per screen pixel (conversion to barycentric coordinates and constraint checking for each subpixel). Bilinear level interpolation is slower than bilinear pixel interpolation sampling but faster than supersampling 16 subpixels per pixel, since it doesn't require additional samples, but might require some additional mipmap computations such as blending to levels in the case of bilinear level interpolation.
	</p><p>
		In terms of memory, supersampling more times per pixel is bound to be the most memory intensive, especially since it uses a larger sample_buffer and then averages it out. This is followed by level sampling, which stores mipmap level information and the texture sample -> screen rasterization, and then finally by pixel sampling which only needs to store the texture sample and rasterization buffer. In terms of quality, supersampling does a great job at producing a good antialias, but the other two methods produce a smooth version of the image that may be more appropriate for certain types of content.
	</p><div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="T6 0 near.png" width="400px"/>
				  <figcaption>L_ZERO P_NEAREST.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="T6 0 lin.png" width="400px"/>
				  <figcaption>L_ZERO P_LINEAR.</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="T6 near near.png" width="400px"/>
				  <figcaption>L_NEAREST P_NEAREST.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="T6 near lin.png" width="400px"/>
				  <figcaption>L_NEAREST P_LINEAR.</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		</div>
		<h2> Task 2: Extra Credit (Anisotropic Filtering) </h2>
		<p> Anisotropic filtering is a way to sample textures in a way that accounts for the direction of the texture. This is useful for textures that are stretched in one direction. I implemented anisotropic filtering by computing the derivatives of the texture coordinates in the x and y directions, then using these derivatives to sample the texture at a rate that is proportional to the stretching in that direction.</p>
		
		<p> In the images below, you can see the difference amongst the various methods of level sampling. Anisotropic sampling produces the clearest possible rendition of the image which is clear at all points, regardless of the level of curvature the texture has to go through.</p>
		<div style="display: flex; flex-direction: column; align-items: center;">
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
			  <tr>
				<td style="text-align: center;">
				  <img src="T6EC Nearest.png" width="400px"/>
				  <figcaption>Nearest.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="T6EC Bilinear.png" width="400px"/>
				  <figcaption>Bilinear.</figcaption>
				</td>
			  </tr>
			  <tr>
				<td style="text-align: center;">
				  <img src="T6EC Trilinear.png" width="400px"/>
				  <figcaption>Trilinear.</figcaption>
				</td>
				<td style="text-align: center;">
				  <img src="T6EC Anisotropic.png" width="400px"/>
				  <figcaption>Anisotropic.</figcaption>
				</td>
			  </tr>
			</table>
		</div>
		<p>In terms of timing, anisotropic sampling is evidently the slowest, since it is the most computationally heavy on the processor.</p>
		<table>
			<thead>
				<tr>
					<th>Test Number</th>
					<th>Nearest</th>
					<th>Bilinear</th>
					<th>Trilinear</th>
					<th>Anisotropic</th>
				</tr>
			</thead>
			<tbody>
				<tr>
					<td>test1.svg</td>
					<td>0.013</td>
					<td>0.011</td>
					<td>0.013</td>
					<td>0.029</td>
				</tr>
				<tr>
					<td>test2.svg</td>
					<td>0.02</td>
					<td>0.019</td>
					<td>0.025</td>
					<td>0.053</td>
				</tr>
			</tbody>
		</table>
	</body>
</html>